# MVP: Quick Start Guide

**Get the interactive dashboard running in < 2 minutes.**

---

## ðŸš€ 30-Second Setup

```bash
cd /Users/supriyarao/visual\ studio/handinhand
source ./activate.sh
python3 recognition_engine_ui.py
```

**That's it.** A window opens with your webcam feed + confidence bars.

---

## ðŸ“Š What You'll See

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONFIDENCE SCORES      Window: 45%  â”‚
â”‚ GREETING    [====]    0.45          â”‚
â”‚ YOU         [==]      0.12          â”‚
â”‚ GO          [===]     0.28          â”‚
â”‚ WHERE       [ ]       0.03          â”‚
â”‚                                     â”‚
â”‚  (Your webcam video here)           â”‚
â”‚                                     â”‚
â”‚  âš ï¸ AMBIGUOUS (0.45)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**As you sign**:

- Bars rise/fall in real-time âœ¨
- Window fills from 0 â†’ 100%
- Status changes to âœ… VERIFIED when confident
- Cooldown timer appears for 2 seconds

---

## ðŸŽ® Commands

### Basic

```bash
# Standard (with dashboard)
python3 recognition_engine_ui.py

# With ghost skeleton overlay (debug mode)
python3 recognition_engine_ui.py --debug

# With custom cooldown (in milliseconds)
python3 recognition_engine_ui.py --cooldown 3000

# Demo mode (5 seconds per frame)
python3 recognition_engine_ui.py --delay 5000
```

### With Socket.io (Future Avatar)

```bash
# Send "sign_recognized" events to server
python3 recognition_engine_ui.py --socket-url http://localhost:5000

# (Server receives: {"concept": "GREETING", "score": 0.92, "timestamp": ...})
```

### Keyboard

- **ESC** or **q** = Quit
- **r** = Reset window

---

## âœ… Test Sequence

### Test 1: Visual Feedback

1. Run: `python3 recognition_engine_ui.py --debug`
2. Slowly raise your hand â†’ Watch GREETING bar rise
3. Lower hand â†’ Watch bar drop
4. **Result**: Bars move = algorithm tracking âœ…

### Test 2: Recognition

1. Run: `python3 recognition_engine_ui.py`
2. Make the HELLO sign (ASL wave)
3. Wait for window to fill (â‰ˆ1 second of continuous gesture)
4. **Expected**: Status shows "âœ… VERIFIED: GREETING (0.92)"
5. Repeat for YOU, GO, WHERE

### Test 3: Cooldown

1. Run: `python3 recognition_engine_ui.py`
2. Sign HELLO â†’ Status shows "âœ… VERIFIED"
3. Immediately sign HELLO again
4. Timer shows "Cooldown: 1.8s" (prevents re-trigger)
5. Wait 2 seconds â†’ Can sign again
6. **Result**: Prevents accidental double-counting âœ…

### Test 4: All 4 Concepts

| Concept      | Gesture             | Expected          | Status |
| ------------ | ------------------- | ----------------- | ------ |
| **GREETING** | Wave hand           | GREETING bar high | [ ]    |
| **YOU**      | Point gesture       | YOU bar high      | [ ]    |
| **GO**       | Moving away         | GO bar high       | [ ]    |
| **WHERE**    | Questioning gesture | WHERE bar high    | [ ]    |

**Target**: 95%+ accuracy on each

---

## ðŸ› Troubleshooting

### Issue: Camera Not Opening

```bash
# Try alternate camera
python3 recognition_engine_ui.py --camera 1
```

### Issue: Bars Not Moving

- Check lighting (MediaPipe needs good brightness)
- Move hands closer to camera
- Verify camera is not blocked: `python3 -c "import cv2; cap = cv2.VideoCapture(0); print(cap.isOpened())"`

### Issue: Recognition Not Working

1. Run with debug to see ghost skeleton:
   ```bash
   python3 recognition_engine_ui.py --debug
   ```
2. Check if your gesture aligns with golden skeleton
3. Try more pronounced hand movements

### Issue: "ModuleNotFoundError: No module named 'socketio'"

- This is OK! Socket.io is optional.
- If you want it: `pip install python-socketio`
- Ignore if just testing locally

---

## ðŸ“ˆ Performance

| Metric       | Expected                        |
| ------------ | ------------------------------- |
| **FPS**      | 30 (smooth video)               |
| **Latency**  | < 200ms from sign to bar update |
| **Memory**   | ~200MB                          |
| **Accuracy** | > 95% on 4 concepts             |

---

## ðŸŽ¯ Success Indicators

âœ… **You know it's working when**:

- Bars rise/fall smoothly as you move hands
- Window fills to 100% after ~1 second of gesture
- Status changes to âœ… VERIFIED when you hold a sign
- Cooldown timer appears after each match
- No console errors

---

## ðŸš€ Next Steps

After confirming MVP works:

1. **Measure Accuracy** (15 min)
   - Sign each concept 20 times
   - Count correct recognitions
   - Target: > 95%

2. **Setup Avatar Server** (30 min)
   - Start local Socket.io server
   - Run: `python3 recognition_engine_ui.py --socket-url http://localhost:5000`
   - See events flowing to server

3. **Build Avatar (Phase 3)** (1-2 weeks)
   - React component that listens for `sign_recognized` events
   - Load BSL animation based on concept_id
   - Play animation on match

---

## ðŸ’¡ Pro Tips

**For Best Recognition**:

- âœ… Good lighting (face the window)
- âœ… Clear, deliberate hand movements
- âœ… Wait for window to fill completely (100%)
- âœ… Hold gesture for 1-2 seconds

**For Debugging**:

- Use `--debug` to see ghost skeleton overlay
- Compare your hands to golden signature
- If misaligned, adjust gesture position

**For Demo**:

- Use `--delay 5000` for slow-motion (5s per frame)
- Easy to film/show others
- See algorithm thinking step-by-step

---

## ðŸ“Š Dashboard Reference

| Element               | Meaning                               |
| --------------------- | ------------------------------------- |
| **Green bar**         | High confidence (â‰¥ 0.80)              |
| **Orange bar**        | Medium confidence (0.50-0.80)         |
| **Red bar**           | Low confidence (< 0.50)               |
| **Window: 75%**       | 75% of 30 frames accumulated          |
| **âœ… VERIFIED**       | Recognition confirmed (Tier 4 passed) |
| **âš ï¸ AMBIGUOUS**      | Similar scores (need clearer gesture) |
| **âŒ LOW CONFIDENCE** | Score too low                         |
| **Cooldown: 1.2s**    | Wait before next can trigger          |

---

## ðŸ”§ Fine-Tuning

If recognition not accurate, edit `recognition_engine_ui.py` thresholds:

```python
# Line ~20-30
COSINE_SIM_THRESHOLD = 0.80      # Lower = more permissive (0.75)
TIER_4_GAP_THRESHOLD = 0.15      # Lower = less strict (0.10)
WINDOW_SIZE = 30                 # Longer = smoother (40)
```

Then rerun:

```bash
python3 recognition_engine_ui.py
```

---

## âœ¨ Summary

**MVP Dashboard is**:

- âœ… Simple (1 command to run)
- âœ… Visual (bars show what's happening)
- âœ… Accurate (Tier 4 validation)
- âœ… Ready (Socket.io for avatar later)
- âœ… Fast (30 FPS)

**Ready to test?**

```bash
python3 recognition_engine_ui.py --debug
```

Then sign a word and watch the bars move! ðŸŽ‰

---

**File**: [recognition_engine_ui.py](../recognition_engine_ui.py)  
**Time to first run**: 30 seconds  
**Expected accuracy**: 95%+

Let's go! ðŸš€
